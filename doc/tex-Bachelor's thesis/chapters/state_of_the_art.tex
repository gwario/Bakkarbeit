\newglossaryentry{UML}
{
  name={Unified Modeling Language},
  description={The Unified Modeling Language provides a standard way for modeling artifacts of software engineering. See \url{http://www.uml.org/} for detailed information on UML.}
}

\newglossaryentry{GraphTrace}
{
  name={GraphTrace},
  description={This paper describes GraphTrace, a tool we have developed to assist in understanding object-oriented programs, GraphTrace allows a user to create displays revealing different aspects of the structure of an object-oriented program, and then to animate these displays in order to visually understand how the program works.}
}

\chapter{Analysis of existing approaches}
\label{chap:StateOfTheArt}

The focus here lies on so called E type software systems. E stands for evolving \cite{Cook:2006:ESS:1115566.1115567}, most of the real world software systems are type E. These systems are of particular interest since they underlie continuous changes throughout their whole life cycle. Thus understanding existing code, which might not be well documented, is crucial for the maintenance of those systems.

\section{Program comprehension}

Program comprehension can be gained through several approaches. First of all, reading the code.
In \cite{Basili:1997:EPR:257260.257262}, Basili et al. approach the concept of reading on a very fundamental level. The natural way to learn writing, is to learn to read first. The reading then forms a model for our writing.  His research shows that reading is most effective compared to testing. This suggests, that readability of code does impact the efficiency of failure discovery. According to Basili et al., the most severe problem is the fact that programming languages are learned the other way round. We first learn to write code and then learn to read it. Furthermore, the ability to read code is not properly addressed in education. The syntactical flexibility, Forth provides compared to other languages(and paradigms), allows it to achieve a very natural seeming reading experience. Thus our skills in natural languages could become in handy and make program reading and thus understanding even more efficient. This would in the end result in higher code quality in terms of failures and unexpected or unintended behavior.

There emerged several strategies on how to read and understand a program\cite{Storey:1999:CDE:308936.308940}\cite{Storey:1997:PUT:832304.836998}:
\subsubsection*{Top down program comprehension}
Using the top down strategy, the reader begins on the highest level of abstraction, the main purpose of the program and then builds a hierarchy by refining it into sub tasks until the lowest level of abstraction is reached.
\subsubsection*{Bottom up program comprehension} Using the bottom up strategy, the reader builds the mental model by grouping low level parts of code building high levels abstraction until the whole program is understood.
\subsubsection*{Knowledge based program comprehension} The knowledge based strategy, allows both, the bottom up and the top down approach. The assumption is, that programmers have a certain mental model of the software, this model is evolved by both refinement and abstraction.
\subsubsection*{Systematic and as-needed program comprehension} This strategy embodies detailed reading as well as only focusing on the code necessary to fulfill the task at hand.
\subsubsection*{Integrated approaches of program comprehension} This strategy allows freely switching between the top down, the bottom up and the knowledge based approach.
\\\\
As Storey et al.\cite{Storey:1999:CDE:308936.308940} points out, there are certain factors which influence the choice programmers take. Thus programming environments should provide methods to support all of these strategies.\hl{(See later section --- make a connection to the strategie later?! or leave out)}
\\
Since software evolves throughout its whole life cycle, also the before mentioned mental model, of the reader has to evolve. It has to be kept in sync with the software system. This suggests, that it is essential to keep all types of artifacts(documentation, source level documentation, graphics,...) up to date.

\section{Analysis to support program understanding}

Besides reading of the source code and other textual documentation, there are also other methods to increase program understanding.

\subsection{Dynamic analysis}

Dynamic analysis is performed on the image of a program, executed on a real or virtual processor. The advantage is, that due to the availability of the data to be manipulated, the actual behavior of a program can be investigated. The major drawback however is that there exists only an incomplete view of the software system at hand\cite{Ball:1999:CDA:318774.318944}. Dynamic analysis is a very efficient way to evolve or correct the mental model of developers, but not to create it. In large software systems, some scenarios might not occur during analysis.
\hl{TODO einfach weglassen? I will distinct here between two categories of dynamic analysis:}
\hl{TODO... ???}
\begin{itemize}
\item interactive\\
	The characteristics of interactive(stepped debugging, interpretative execution) approaches, is that the program is still executing during the analysis and thus time is a critical factor. This makes some analysis methods like performance analysis impossible. In networked environment, timeouts can make interactive analysis very hard.
\item non interactive(real-time and post-mortem)\\
	In real-time analysis(log analysis, trace analysis), data changes very quickly, which can make the task of tracking execution scenarios very resource intensive. In contrast, in post-mortem analysis(log analysis, trace analysis), the processing of very large files becomes a problem.
\end{itemize}


\begin{itemize}
\item \hl{INTEGRATE THIS?: observer effect} \\
Andrews, J. (1997). Testing using log file analysis: tools, methods, and issues.
In Proc. International Conference on Automated Software Engineering (ASE), pages 157â€“
166. IEEE Computer Society Press
\item scalability \\
Zaidman, A. (2006). Scalability Solutions for Program Comprehension through Dynamic
Analysis. PhD thesis, University of Antwerp
\item debugging -> different kind of paradigms and languages and tools\\
see @incollection{reiss1993trace,
title={Trace-based debugging},
author={Reiss, Steven P},
booktitle={Automated and Algorithmic Debugging},
pages={305--314},
year={1993},
publisher={Springer}
}
\end{itemize}

\subsection{Static analysis}

Although this thesis focuses on dynamic analysis, for the sake of completeness, also static analysis should be mentioned here.
Static analysis is performed on the source code. Therefore and in contrast to dynamic analysis, it has the capability to provide a complete view of the software at hands. The drawback is that there is no actual data present and thus there are no means of covering the actual data follow and the manipulation of data.

\section{Existing approaches}

\subsection{Gforth/Forth}

In this section I'm going to present the tools, Gforth/Forth provides to support program understanding and maintenance\footnote{For further tools see \url{https://www.complang.tuwien.ac.at/forth/gforth/Docs-html/Programming-Tools.html\#Programming-Tools}}.

\subsubsection*{Examining data and code}
Gforth provides several tools to display data and code, which supports program understanding and software maintenance.\\
For displaying data, the most important words are \emph{.}, \emph{.s}, \emph{."}, \emph{type} and \emph{dump}.\\
\emph{.} and \emph{.s} simply display elements of the stack, there are also words to visualize the other stacks.
The words \emph{."} and \emph{type} display text and \emph{dump} displays memory areas(address, hex and ascii).
\textasciitilde\textasciitilde\:  displays the location of itself in the source-file(file and line number) as well as the data stack.\\
All these words can be utilized to display logging information.\\
They are usable in interactive as well in non-interactive analysis.\\
There are also words to investigate the inner workings of other words. 
\emph{see} displays the definition of words written in Forth. It can be used to quickly look at the behavior of words provided by Gforth without looking into source-files. The use of \emph{see} and its relatives only makes sense in interactive analysis.

\subsubsection*{status.fs}
Status.fs is included in Gforth(since 0.7.0). It opens a separate xterm window, displaying the current number base, the float stack, the data stack and the current search order. The view is updated after each execution in the interpreter. Thus it is only useful for interactive analysis.

\subsubsection*{Stepping debugger}
\emph{dbg}\footnote{For further information see: \url{https://www.complang.tuwien.ac.at/forth/gforth/Docs-html/Debugging.html\#Debugging}}, the stepping debugger, supports among others, single step, step into, step over as well as break points. It displays the address of the word to be executed and the content of the data stack after its execution. \emph{dbg} is only usable for interactive analysis.

\subsubsection*{Assertions}
Assertions\footnote{See \url{https://www.complang.tuwien.ac.at/forth/gforth/Docs-html/Assertions.html\#Assertions}} can be used to verify, that the program, at a certain point, is in a certain state. For example pre-conditions and post-conditions of words could be implemented using assertions. It is also possible to prevent code from breaking during maintenance activities. The word \emph{assert(} starts the assertion, the following words until the \emph{)} are executed and have to leave a flag on the stack. If that flag is true, the asserted condition is meet, otherwise, the execution of the program ends and the location of the failed assertion is displayed(source file and line number).\\
There are several assertion levels and by setting the \emph{assert-level}, assertions can also be deactivated.

\subsubsection*{Documentation}
Thorough and up-to-date documentation is undoubtedly important, this also applies to concatenative languages. Besides behavior description of words, since forth is by default an untyped language, there is also a special kind of documentation encouraged to ease the understanding of words, namely the stack effect comment\footnote{See \url{https://www.complang.tuwien.ac.at/forth/gforth/Docs-html/Notation.html\#Notation}}. It is written next to the name of the defined word and contains the number and kind of elements on the stack which are manipulated by the word. These comments describe the state of the stack before and after the execution of a word. In these comments, there is also a distinction to be made between interpretation, compile and run-time behavior.

\subsection*{Words and word lists}
Like in any other language, words should be named expressively. However sometimes, it may not be avoidable to reuse names. Forth provides an elegant mechanism, called word lists\footnote{For more information on word lists, see \url{http://www.complang.tuwien.ac.at/forth/gforth/Docs-html/Word-Lists.html\#Word-Lists}}, to address these issues and to organize words. With word lists, words can be defined in a certain context. Like in natural languages words can have a different meaning in separate contexts. Using word lists, developers can prevent name clashes and separate interface words from internal words. In large projects it might be necessary to define a naming strategy.

\subsection*{Factoring}
As in any other programming language, it is necessary to split the overall problem down into manageable, less complex sub problems. In concatenative languages this is also referred to as factoring. Factoring helps keeping definitions short(and thus easier to understand), reusable and easier to test(\url{https://www.complang.tuwien.ac.at/forth/gforth/Docs-html/Factoring-Tutorial.html}).

\subsection*{Aliasing}
In Gforth, there can be multiple aliases\footnote{See https://www.complang.tuwien.ac.at/forth/gforth/Docs-html/Aliases.html} for one word. Aliases can be used to use the same underlying implementation in different contexts, to make code more readable.

\subsection*{Emacs forth-mode}

The emacs forth-mode(gforth.el, which is based on forth.el) provides many helpful features\footnote{For a more information see \url{https://www.complang.tuwien.ac.at/forth/gforth/Docs-html/Emacs-and-Gforth.html\#Emacs-and-Gforth}} to ease the writing of Forth. Most notable, related to program understanding:
\begin{itemize}
\item Word documentation lookup
\item Jump to line from, error messages, debug output, failed assertions and \emph{\textasciitilde\textasciitilde} output
\item Highlighting
\item Indention handling
\end{itemize}

\subsection*{Kgforth}

There has also been an afford to integrate some of those tools into a graphical development environment. The project is called Kgforth\footnote{\url{http://sourceforge.net/projects/kgforth/}: Kgforth is a simple IDE for the gforth interpreter/compiler for KDE 2.** 
It provides an editor, gforth window,debug and dump window, forth toolbar and menu.}, but its development seems to be discontinued.

\section{Applicability of methods for other paradigms to concatenative languages}

In this section I will present a hand full of visualization methods and discuss their applicability to Gforth/Forth. 

\subsection*{Sequence diagram, interaction diagram and scenario diagram}

The \gls{UML} sequence diagram can be used to model event sequences on any level of abstraction. Since I left out object oriented Forth and there is no standard for concurrency, the word-only level provides little help. On this level, the actors would be represented by words and the messages\footnote{The edges in UML's sequence diagram are called messages.} would represent word executions. Therefore the sequence diagram would degrade to a list. On the system level although, the sequence diagram can provide useful information on the interaction between system components. The scenario diagram as implemented by \cite{Koskimies:1996:SUS:871313}, is essentially the same as the sequence \hl{diagram and the interaction diagram which has been proposed by Jacobson, 1992 --- Citation unclear...}.
\\
Since system level visualization is applicable to almost any paradigm and word level visualization does not seem promising for dynamic analysis, I will not investigate the benefits of those diagrams in this thesis.

\subsection*{Hierarchical edge bundles}
Hierarchical edge bundles as proposed by \cite{Holten:2006:HEB:1187627.1187772} display hierarchic and non hierarchic relations between nodes. In context of forth, word execution can be mapped to non hierarchic relations and directory/file tree and the definition could be the hierarchic relations. Like in object oriented systems, the proper organization of directories, files and word definitions has to be considered to make such a visualization helpful.
Another possible mapping could depend on word list as words hierarchic and word execution as non hierarchic relation.
\\
The hierarchic edge bundle can be used for interactive and non-interactive(real-time) dynamic analysis. In the following chapter I will analyze both possibilities using a real forth software as an example.

\subsection*{Information murals and massive sequence view}
The information mural was initially proposed by \cite{Jerding:1998:IMT:614271.614408}. A modified version, the mass sequence view, was later proposed by \cite{Cornelissen2009}. It turns the horizontal scrolling into vertical scrolling and also included the hierarchic aspect be more suitable. As with the hierarchical edge bundles, the usefulness of the hierarchical element depends highly on the organization of the software system at hand.
\\
As well as the hierarchic edge bundle, these two methods can be used for interactive and non-interactive(post-mortem) dynamic analysis. In the following chapter I will analyze the massive sequence view using a real forth software as an example.

\subsection*{High-Level polymetric views}
Polymetric views\cite{Ducasse:2004:HPV:977397.977739} are a very interesting and promising approach to grasp the behavior of very large systems. In polymetric views, system attributes or measures are mapped to attributes of a graph. The attributes proposed by\cite{Ducasse:2004:HPV:977397.977739}, are position, height, width, color and the relations(and the thickness) between rectangles, representing aspects of the software to analyze. In terms of forth, the mapping to words seems most obvious. This would result in some kind of a word cloud with additional information attached. This could be most valuable, when used with the appropriate metrics, to analyze and optimize performance. Another advantage is, that there is no complete, but only condensed\hl{evt footnote erklÃ¤rung was das bedeutet} data required.
\\
This method is suitable for interactive as well as non-interactive analysis. In the following chapter I will analyze a polymetric view of real software as an example.

\subsection*{Fisheye views}
Fisheye views were first proposed by \cite{Furnas:1986:GFV:22627.22342} and formulated by \cite{Storey:1995:GLA:647547.728600} and \cite{Sarkar:1994:GFV:198366.198384}. The essence of fisheye views is a principle also found in nature. It's basically described as a function, expressing the degree of interest of an subject, depending on an a priori importance and the distance from the current point of view. Growing distance lowers the degree of interest.
\\
This method is related to polymetric views, as mentioned above.\hl{is it a special case of a polymetric view?!}

\subsection*{Execution pattern view}
The execution pattern view, proposed by \cite{Pauw98executionpatterns}, visualize large traces in a scalable manner and helps to identify execution patterns. I represent an interesting evolution of simple sequence diagrams and interaction diagrams.
\\
Since it is somehow related to the massive sequence view, I will not pursue this approach in detail.

\subsection*{Method invocation view and taxonomy view}
The tool \gls{GraphTrace}\cite{Kleyn:1988:GOS:62084.62101} is meant to analyze object oriented programs. It provides a method invocation view and a taxonomy view. Although the method invocation approach of GraphTrace seems not practical for forth programs, the authors mentioned two very interesting ideas.
\begin{itemize}
\item Displaying variable access:\\
	The idea of showing words which access variables and the other way round, showing which words access a specific variable is very interesting. Thus it would be easier to track the global state of a program.
\item Concurrent views:\\
	The authors of \cite{Kleyn:1988:GOS:62084.62101} present a quiet interesting analogy. They compare the execution of a program with a tennis and football and refer to the multiple perspectives necessary to understand all aspects of a match and the whole outcome.
\end{itemize}

The variable access graph in a tree like visualization as in GraphTrace seems highly useful since variables represent a global program state, which can increase complexity. Although this approach seems to make only sense for in static analysis, I will analyze the variable access graph of real software as an example in the next chapter.

\subsection*{Frequency spectrum analysis}

The frequency spectrum analysis as proposed by \cite{Ball:1999:CDA:318774.318944} represents an interesting approach. It is similar to parametric views as mentioned before, but the visualization is not graphical but textual. The word execution frequency could provide valuable information about the actual performed work and incorporated with execution time, it could help in understanding programs and support performance analysis. In \cite{Ball:1999:CDA:318774.318944}, Ball shows the application of frequency spectrum analysis at the example of an obfuscated c program, but his approach should also be applicable to concatenative languages.

Since this is not the main focus of this thesis, I wont discuss this approach any further.

\section{Methods to support code readability and improve program understanding}

In this section I will suggest methods to write better and more natural readable code as well as methods easy understanding of existing programs.
\\
A very important question is, how developers can be assisted to write more readable code. Concatenative languages are flexible enough to produce code very similar to natural languages, but how can this style be encouraged? In my opinion, the top down strategy and extensive use of factoring, is the key to produce readable Forth code in large software systems.
\\
To encourage high code quality and the development environment should provide hints based on static analysis.

\subsection{Common issues and possible solutions for writing readable code}

It is not possible to make every word completely readable and the perceived readability also depends on the experience of the developer. At some point  it always comes down to longer combinations of "nip tuck over rot", this is hardly avoidable at the lowest level. Thus, proper documentation of words is essential. It is pretty obvious, that stack effect comment\footnote{See \url{https://www.complang.tuwien.ac.at/forth/gforth/Docs-html/Stack\_002dEffect-Comments-Tutorial.html\#Stack\_002dEffect-Comments-Tutorial}} in Forth, are a must have, but also the behavior of the word should be documented for complex or not very natural to read words\footnote{Most notable \\G in Gforth. See \url{https://www.complang.tuwien.ac.at/forth/gforth/Docs-html/Comments.html\#Comments}}. Another advantage of word definition comments is the possibility of automated documentation generation.\\
But using this approach, the developers can stick to natural language like words until there is no more factoring possible and the words have to be implemented in Gforth words.
\\
Another common problem are very long word definitions, they tend to increase the amount of brain capacity required to understand their behavior. To address this problem, the word hierarchy created by factoring, should be kept slim and deep. One approach herer could be to place a hint on word definitions which exceed a certain amount of lines or words or different words and suggest further factoring.
\\
A tool to make code reading more natural, is aliasing. By defining aliases for a certain word, its functionality can be used in different contexts and still read very natural.

\subsection{Common issues and possible solutions to u ease program understanding}

To understand code, the systematic approach turned out to be most efficient\cite{Robillard:2004:EDI:1042203.1042417}. To ease afford of finding the definition of words used at a certain point, a hyperlink like referencing mechanism can be used[cite the visualization paper with the hyperlink feature].\\
As stated by \gls{Charles D. Moore} in \cite{Biancuzzi:2009:MPC:1592983}: "... The challenge there is 1) deciding which words are useful, and 2) remembering them all.", when programs get larger, the amount of words can grow big. Thus it is suggested to have some sort of a dictionary to search the whole vocabulary by name, stack effect comment, word definition documentation and provide a reverence to where they are used. Auto completion can also help a lot in finding words previously defined.


\begin{itemize}

\item other data structures and variables should be displayed
	\begin{itemize}
	\item memory maybe like \cite{ReissProgrammingEnvironments1995} or \cite{Aftandilian:2010:HIH:1879211.1879222} but since there is no underlying object orientation and no standardized oo system this would be hard do accomplish
	\item fisheye or word cloud like display(tree or sugiyama as of \cite{Storey:1997:IVT:857188.857642})
	\end{itemize}

\item interactive program manipulation: state of the system before a word, after a word and by clicking on the word jumping to its definition or inserting it and there also providing those features

\item goal-oriented strategy: the definition of an execution scenario such that only the parts of interest of the software system are analyzed (Koenemann and Robertson, 1991; Zaidman,
2006).

\item code analysis and visualization facilities see chapter 2 TODO
\end{itemize}

\subsection{software maintenance}

\begin{itemize}
\item types of maintenance
\item find bugs and fix them
\item find the right place to implement a new feature.
\item find the right place to modify a feature.
\end{itemize}

\subsection{program comprehension}

\begin{itemize}
\item structured approach
\item thorough reading is the most efficient[cite]
\item about the mental model building
\item keeping the mental model up to date
\item keeping artifacts up to date
\end{itemize}